{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41eecb42-fa93-4bf6-a229-5f6b937878df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6dc5881-d4a8-4a3a-b7eb-ebf1ef217e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LIKE_EMAIL\": True}]\n",
    "matcher.add(\"EMAIL_ADDRESS\", [pattern])\n",
    "doc = nlp(\"This is an email address: wmattingly@aol.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50f54d70-9003-4ae7-b5c3-e4a5174cc03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16571425990740197027, 6, 7)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee46b4a-888a-487e-9c19-90e871694a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EMAIL_ADDRESS'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab[matches[0][0]].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6918d3a-7e6b-4b81-92d3-93fe3daed62c",
   "metadata": {},
   "source": [
    "Attributes Taken by Matcher¶\n",
    "ORTH - The exact verbatim of a token (str)\n",
    "\n",
    "TEXT - The exact verbatim of a token (str)\n",
    "\n",
    "LOWER - The lowercase form of the token text (str)\n",
    "\n",
    "LENGTH - The length of the token text (int)\n",
    "\n",
    "IS_ALPHA\n",
    "\n",
    "IS_ASCII\n",
    "\n",
    "IS_DIGIT\n",
    "\n",
    "IS_LOWER\n",
    "\n",
    "IS_UPPER\n",
    "\n",
    "IS_TITLE\n",
    "\n",
    "IS_PUNCT\n",
    "\n",
    "IS_SPACE\n",
    "\n",
    "IS_STOP\n",
    "\n",
    "IS_SENT_START\n",
    "\n",
    "LIKE_NUM\n",
    "\n",
    "LIKE_URL\n",
    "\n",
    "LIKE_EMAIL\n",
    "\n",
    "SPACY\n",
    "\n",
    "POS\n",
    "\n",
    "TAG\n",
    "\n",
    "MORPH\n",
    "\n",
    "DEP\n",
    "\n",
    "LEMMA\n",
    "\n",
    "SHAPE\n",
    "\n",
    "ENT_TYPE\n",
    "\n",
    "_ - Custom extension attributes (Dict[str, Any])\n",
    "\n",
    "OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00da78b2-1cc0-4842-a537-20456aee2d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America. It consists of 50 states, a federal district, five major unincorporated territories, 326 Indian reservations, and some minor possessions.[j] At 3.8 million square miles (9.8 million square kilometers), it is the world's third- or fourth-largest country by total area.[d] The United States shares significant land borders with Canada to the north and Mexico to the south, as well as limited maritime borders with the Bahamas, Cuba, and Russia.[22] With a population of more than 331 million people, it is the third most populous country in the world. The national capital is Washington, D.C., and the most populous city is New York.\n",
    "\n",
    "Paleo-Indians migrated from Siberia to the North American mainland at least 12,000 years ago, and European colonization began in the 16th century. The United States emerged from the thirteen British colonies established along the East Coast. Disputes over taxation and political representation with Great Britain led to the American Revolutionary War (1775â€“1783), which established independence. In the late 18th century, the U.S. began expanding across North America, gradually obtaining new territories, sometimes through war, frequently displacing Native Americans, and admitting new states; by 1848, the United States spanned the continent. Slavery was legal in the southern United States until the second half of the 19th century when the American Civil War led to its abolition. The Spanishâ€“American War and World War I established the U.S. as a world power, a status confirmed by the outcome of World War II.\n",
    "\n",
    "During the Cold War, the United States fought the Korean War and the Vietnam War but avoided direct military conflict with the Soviet Union. The two superpowers competed in the Space Race, culminating in the 1969 spaceflight that first landed humans on the Moon. The Soviet Union's dissolution in 1991 ended the Cold War, leaving the United States as the world's sole superpower.\n",
    "\n",
    "The United States is a federal republic and a representative democracy with three separate branches of government, including a bicameral legislature. It is a founding member of the United Nations, World Bank, International Monetary Fund, Organization of American States, NATO, and other international organizations. It is a permanent member of the United Nations Security Council. Considered a melting pot of cultures and ethnicities, its population has been profoundly shaped by centuries of immigration. The country ranks high in international measures of economic freedom, quality of life, education, and human rights, and has low levels of perceived corruption. However, the country has received criticism concerning inequality related to race, wealth and income, the use of capital punishment, high incarceration rates, and lack of universal health care.\n",
    "\n",
    "The United States is a highly developed country, accounts for approximately a quarter of global GDP, and is the world's largest economy. By value, the United States is the world's largest importer and the second-largest exporter of goods. Although its population is only 4.2% of the world's total, it holds 29.4% of the total wealth in the world, the largest share held by any country. Making up more than a third of global military spending, it is the foremost military power in the world; and it is a leading political, cultural, and scientific force internationally.[23]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6294190-8cba-4184-a370-922f2e501dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443d9871-c811-4aaa-b3b7-5cd77a209b19",
   "metadata": {},
   "source": [
    "Grabbing all Proper Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5627f41f-73a2-4b54-afc9-2078cf03e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PROPN\"}]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern])\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cbe4021-aae5-45f3-9d7a-0b82179a8d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9906e514-eaa0-4f28-abeb-dda14497fbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3232560085755078826, 2, 3) United\n",
      "(3232560085755078826, 3, 4) States\n",
      "(3232560085755078826, 5, 6) America\n",
      "(3232560085755078826, 7, 8) U.S.A.\n",
      "(3232560085755078826, 9, 10) USA\n",
      "(3232560085755078826, 16, 17) United\n",
      "(3232560085755078826, 17, 18) States\n",
      "(3232560085755078826, 19, 20) U.S.\n",
      "(3232560085755078826, 21, 22) US\n",
      "(3232560085755078826, 24, 25) America\n"
     ]
    }
   ],
   "source": [
    "for match in matches[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b835a12-7e38-41f9-8279-f13602b483fc",
   "metadata": {},
   "source": [
    "Improving it with Multi-Word Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a4fd800-d88c-4dc9-950c-0e002cf34a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "(3232560085755078826, 2, 3) United\n",
      "(3232560085755078826, 2, 4) United States\n",
      "(3232560085755078826, 3, 4) States\n",
      "(3232560085755078826, 5, 6) America\n",
      "(3232560085755078826, 7, 8) U.S.A.\n",
      "(3232560085755078826, 9, 10) USA\n",
      "(3232560085755078826, 16, 17) United\n",
      "(3232560085755078826, 16, 18) United States\n",
      "(3232560085755078826, 17, 18) States\n",
      "(3232560085755078826, 19, 20) U.S.\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern])\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "print (len(matches))\n",
    "for match in matches[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8e4678-d4d8-4038-a43a-b55112c93b89",
   "metadata": {},
   "source": [
    "Greedy Keyword Argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbfb1f1f-848b-4191-9a74-0701884f395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "(3232560085755078826, 449, 453) United Nations Security Council\n",
      "(3232560085755078826, 211, 214) American Revolutionary War\n",
      "(3232560085755078826, 283, 286) American Civil War\n",
      "(3232560085755078826, 313, 316) World War II\n",
      "(3232560085755078826, 426, 429) International Monetary Fund\n",
      "(3232560085755078826, 2, 4) United States\n",
      "(3232560085755078826, 16, 18) United States\n",
      "(3232560085755078826, 32, 34) North America\n",
      "(3232560085755078826, 87, 89) United States\n",
      "(3232560085755078826, 154, 156) New York\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "print (len(matches))\n",
    "for match in matches[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80dccc-b545-453e-9c17-f994624df87c",
   "metadata": {},
   "source": [
    "Sorting it to Apperance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "275ea9b4-4254-4d80-a89d-b3b82c1884b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "(3232560085755078826, 2, 4) United States\n",
      "(3232560085755078826, 5, 6) America\n",
      "(3232560085755078826, 7, 8) U.S.A.\n",
      "(3232560085755078826, 9, 10) USA\n",
      "(3232560085755078826, 16, 18) United States\n",
      "(3232560085755078826, 19, 20) U.S.\n",
      "(3232560085755078826, 21, 22) US\n",
      "(3232560085755078826, 24, 25) America\n",
      "(3232560085755078826, 32, 34) North America\n",
      "(3232560085755078826, 84, 85) area.[d\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key = lambda x: x[1])\n",
    "print (len(matches))\n",
    "for match in matches[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7697abeb-c0ed-4495-9b6b-3179cb86112a",
   "metadata": {},
   "source": [
    "Adding in Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f54a6123-4982-43dc-8135-e241325db62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "(3232560085755078826, 87, 90) United States shares\n",
      "(3232560085755078826, 160, 162) Indians migrated\n",
      "(3232560085755078826, 185, 188) United States emerged\n",
      "(3232560085755078826, 206, 209) Great Britain led\n",
      "(3232560085755078826, 229, 231) U.S. began\n",
      "(3232560085755078826, 259, 262) United States spanned\n",
      "(3232560085755078826, 283, 287) American Civil War led\n",
      "(3232560085755078826, 324, 327) United States fought\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}, {\"POS\": \"VERB\"}]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key = lambda x: x[1])\n",
    "print (len(matches))\n",
    "for match in matches[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4371ad6-f28c-4a74-84d8-666db43d41d4",
   "metadata": {},
   "source": [
    "Finding Quotes and Speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5fd86de-a347-4dd2-b38e-756a68fd9501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open (\"alice.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60a1db2c-34a8-4819-a082-43458bdea8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n"
     ]
    }
   ],
   "source": [
    "text = data[0][2][0].replace( \"`\", \"'\")\n",
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "715532c1-e884-40c9-bff8-7fe75f5ff0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(3232560085755078826, 47, 58) 'and what is the use of a book,'\n",
      "(3232560085755078826, 60, 67) 'without pictures or conversation?'\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key = lambda x: x[1])\n",
    "print (len(matches))\n",
    "for match in matches[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6ee47-7e97-4fa1-96a6-aa92b96c9ca8",
   "metadata": {},
   "source": [
    "Find Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce2df2e1-b419-45d1-8137-249124e91641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(3232560085755078826, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n"
     ]
    }
   ],
   "source": [
    "speak_lemmas = [\"think\", \"say\"]\n",
    "text = data[0][2][0].replace( \"`\", \"'\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern1 = [{'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}, {\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}}, {\"POS\": \"PROPN\", \"OP\": \"+\"}, {'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern1], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key = lambda x: x[1])\n",
    "print (len(matches))\n",
    "for match in matches[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2f9ce7-1412-4667-b5dc-157c46dfc32d",
   "metadata": {},
   "source": [
    "Problem with this Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "363c6660-7620-4844-a013-7a5cdbe77b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(3232560085755078826, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for text in data[0][2]:\n",
    "    text = text.replace(\"`\", \"'\")\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    matches.sort(key = lambda x: x[1])\n",
    "    print (len(matches))\n",
    "    for match in matches[:10]:\n",
    "        print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e707200d-de52-4679-9805-6938b87b9341",
   "metadata": {},
   "source": [
    "Adding More Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ead08891-16ed-4b65-bbe5-f602c50ad06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(3232560085755078826, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "(3232560085755078826, 0, 6) 'Well!' thought Alice\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "(3232560085755078826, 57, 68) 'which certainly was not here before,' said Alice\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "speak_lemmas = [\"think\", \"say\"]\n",
    "text = data[0][2][0].replace( \"`\", \"'\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern1 = [{'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}, {\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}}, {\"POS\": \"PROPN\", \"OP\": \"+\"}, {'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}]\n",
    "pattern2 = [{'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}, {\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}}, {\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
    "pattern3 = [{\"POS\": \"PROPN\", \"OP\": \"+\"},{\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}}, {'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern1, pattern2, pattern3], greedy='LONGEST')\n",
    "for text in data[0][2]:\n",
    "    text = text.replace(\"`\", \"'\")\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    matches.sort(key = lambda x: x[1])\n",
    "    print (len(matches))\n",
    "    for match in matches[:10]:\n",
    "        print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c397606-4c67-4db1-9847-3ba4cafb8850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
